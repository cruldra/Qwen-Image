{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b590c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install ./diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20474daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffusers version: 0.36.0.dev0\n",
      "torch version: 2.8.0\n",
      "transformers version: 4.55.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "print(\"diffusers version:\", version(\"diffusers\"))\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"transformers version:\", version(\"transformers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05899a1d-3b79-4c36-8f85-17cc072ce52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (4.67.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from accelerate) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.7.0)\n",
      "Requirement already satisfied: requests in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: decorator in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\sources\\qwen-image\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 15.5 MB/s  0:00:00\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets, accelerate\n",
      "\n",
      "   -------------------- ------------------- 2/4 [ipywidgets]\n",
      "   -------------------- ------------------- 2/4 [ipywidgets]\n",
      "   -------------------- ------------------- 2/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [accelerate]\n",
      "   ------------------------------ --------- 3/4 [accelerate]\n",
      "   ------------------------------ --------- 3/4 [accelerate]\n",
      "   ------------------------------ --------- 3/4 [accelerate]\n",
      "   ------------------------------ --------- 3/4 [accelerate]\n",
      "   ------------------------------ --------- 3/4 [accelerate]\n",
      "   ------------------------------ --------- 3/4 [accelerate]\n",
      "   ---------------------------------------- 4/4 [accelerate]\n",
      "\n",
      "Successfully installed accelerate-1.10.0 ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "# Âú® notebook ÂçïÂÖÉÊ†º‰∏≠ËøêË°å\n",
    "!pip install ipywidgets tqdm accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfc6220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰ΩøÁî®ÁöÑÊòØcpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the pipeline\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.bfloat16\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch_dtype = torch.float32\n",
    "    device = \"cpu\"\n",
    "print(f\"‰ΩøÁî®ÁöÑÊòØ{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286f1572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122f1c90e65c4f309674c0d61841012a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'pooled_projection_dim': 768} were passed to QwenImageTransformer2DModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bef7b2ba72441fa52325591699de9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01472248c8d497f99881a5eace95af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import QwenImagePipeline\n",
    "\n",
    "model_name = \"./models/Qwen-Image\"\n",
    "pipe = QwenImagePipeline.from_pretrained(model_name, torch_dtype=torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdf673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__getattr__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DiffusionPipeline\n\u001b[32m      4\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33m./models/Qwen-Image\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m pipe = \u001b[43mDiffusionPipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mÁÆ°ÈÅìÂ∑≤Âä†ËΩΩÊàêÂäü\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipe\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Sources\\Qwen-Image\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Sources\\Qwen-Image\\.venv\\Lib\\site-packages\\diffusers\\pipelines\\pipeline_utils.py:927\u001b[39m, in \u001b[36mDiffusionPipeline.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;66;03m# 4. Define expected modules given pipeline signature\u001b[39;00m\n\u001b[32m    921\u001b[39m \u001b[38;5;66;03m# and define non-None initialized modules (=`init_kwargs`)\u001b[39;00m\n\u001b[32m    922\u001b[39m \n\u001b[32m    923\u001b[39m \u001b[38;5;66;03m# some modules can be passed directly to the init\u001b[39;00m\n\u001b[32m    924\u001b[39m \u001b[38;5;66;03m# in this case they are already instantiated in `kwargs`\u001b[39;00m\n\u001b[32m    925\u001b[39m \u001b[38;5;66;03m# extract them here\u001b[39;00m\n\u001b[32m    926\u001b[39m expected_modules, optional_kwargs = \u001b[38;5;28mcls\u001b[39m._get_signature_keys(pipeline_class)\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m expected_types = \u001b[43mpipeline_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_signature_types\u001b[49m()\n\u001b[32m    928\u001b[39m passed_class_obj = {k: kwargs.pop(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m expected_modules \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[32m    929\u001b[39m passed_pipe_kwargs = {k: kwargs.pop(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m optional_kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Sources\\Qwen-Image\\.venv\\Lib\\site-packages\\diffusers\\utils\\import_utils.py:644\u001b[39m, in \u001b[36mDummyObject.__getattr__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, key):\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m_load_connected_pipes\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_onnx\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getattr__\u001b[39;49m(\u001b[38;5;28mcls\u001b[39m, key)\n\u001b[32m    645\u001b[39m     requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m._backends)\n",
      "\u001b[31mAttributeError\u001b[39m: 'super' object has no attribute '__getattr__'"
     ]
    }
   ],
   "source": [
    "# from diffusers import DiffusionPipeline\n",
    "\n",
    "\n",
    "# model_name = \"./models/Qwen-Image\"\n",
    "\n",
    "\n",
    "# pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)\n",
    "# print(f\"ÁÆ°ÈÅìÂ∑≤Âä†ËΩΩÊàêÂäü{pipe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65566c8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot get CUDA generator without ATen_cuda library. PyTorch splits its backend into two shared libraries: a CPU library and a CUDA library; this error has occurred because you are trying to use some CUDA functionality, but the CUDA library has not been loaded by the dynamic linker for some reason.  The CUDA library MUST be loaded, EVEN IF you don't directly use any symbols from the CUDA library! One common culprit is a lack of -INCLUDE:?warp_size@cuda@at@@YAHXZ in your link arguments; many dynamic linkers will delete dynamic library dependencies if you don't depend on any of their symbols.  You can check if this has occurred by using link on your binary to see if there is a dependency on *_cuda.dll library.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     15\u001b[39m aspect_ratios = {\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m1:1\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[32m1328\u001b[39m, \u001b[32m1328\u001b[39m),\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m16:9\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[32m1664\u001b[39m, \u001b[32m928\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m2:3\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[32m1056\u001b[39m, \u001b[32m1584\u001b[39m),\n\u001b[32m     23\u001b[39m }\n\u001b[32m     25\u001b[39m width, height = aspect_ratios[\u001b[33m\"\u001b[39m\u001b[33m16:9\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     27\u001b[39m image = pipe(\n\u001b[32m     28\u001b[39m     prompt=prompt + positive_magic[\u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     29\u001b[39m     negative_prompt=negative_prompt,\n\u001b[32m     30\u001b[39m     width=width,\n\u001b[32m     31\u001b[39m     height=height,\n\u001b[32m     32\u001b[39m     num_inference_steps=\u001b[32m50\u001b[39m,\n\u001b[32m     33\u001b[39m     true_cfg_scale=\u001b[32m4.0\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     generator=\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.manual_seed(\u001b[32m42\u001b[39m)\n\u001b[32m     35\u001b[39m ).images[\u001b[32m0\u001b[39m]\n\u001b[32m     37\u001b[39m image.save(\u001b[33m\"\u001b[39m\u001b[33mexample.png\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Cannot get CUDA generator without ATen_cuda library. PyTorch splits its backend into two shared libraries: a CPU library and a CUDA library; this error has occurred because you are trying to use some CUDA functionality, but the CUDA library has not been loaded by the dynamic linker for some reason.  The CUDA library MUST be loaded, EVEN IF you don't directly use any symbols from the CUDA library! One common culprit is a lack of -INCLUDE:?warp_size@cuda@at@@YAHXZ in your link arguments; many dynamic linkers will delete dynamic library dependencies if you don't depend on any of their symbols.  You can check if this has occurred by using link on your binary to see if there is a dependency on *_cuda.dll library."
     ]
    }
   ],
   "source": [
    "pipe = pipe.to(device)\n",
    "\n",
    "positive_magic = {\n",
    "    \"en\": \", Ultra HD, 4K, cinematic composition.\", # for english prompt\n",
    "    \"zh\": \", Ë∂ÖÊ∏ÖÔºå4KÔºåÁîµÂΩ±Á∫ßÊûÑÂõæ.\" # for chinese prompt\n",
    "}\n",
    "\n",
    "# Generate image\n",
    "prompt = '''A coffee shop entrance features a chalkboard sign reading \"Qwen Coffee üòä $2 per cup,\" with a neon light beside it displaying \"ÈÄö‰πâÂçÉÈóÆ\". Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written \"œÄ‚âà3.1415926-53589793-23846264-33832795-02384197\".'''\n",
    "\n",
    "negative_prompt = \" \" # Recommended if you don't use a negative prompt.\n",
    "\n",
    "\n",
    "# Generate with different aspect ratios\n",
    "aspect_ratios = {\n",
    "    \"1:1\": (1328, 1328),\n",
    "    \"16:9\": (1664, 928),\n",
    "    \"9:16\": (928, 1664),\n",
    "    \"4:3\": (1472, 1104),\n",
    "    \"3:4\": (1104, 1472),\n",
    "    \"3:2\": (1584, 1056),\n",
    "    \"2:3\": (1056, 1584),\n",
    "}\n",
    "\n",
    "width, height = aspect_ratios[\"16:9\"]\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt + positive_magic[\"en\"],\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_inference_steps=50,\n",
    "    true_cfg_scale=4.0,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
    ").images[0]\n",
    "\n",
    "image.save(\"example.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-image (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

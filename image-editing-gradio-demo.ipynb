{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# ğŸ¨ Qwen å›¾åƒç¼–è¾‘å™¨ - Gradioç‰ˆ\n",
    "\n",
    "åŸºäº Qwen-Image-Edit æ¨¡å‹çš„äº¤äº’å¼å›¾åƒç¼–è¾‘åº”ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–\n",
    "!pip install gradio modelscope diffusers transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from diffusers import QwenImageEditPipeline\n",
    "from modelscope import snapshot_download\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®è®¾å¤‡å’Œæ•°æ®ç±»å‹\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "    print(f\"âœ… ä½¿ç”¨ GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"ğŸ’¾ GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    torch_dtype = torch.float32\n",
    "    print(\"âš ï¸ ä½¿ç”¨ CPUï¼ˆå»ºè®®ä½¿ç”¨GPUä»¥è·å¾—æ›´å¥½æ€§èƒ½ï¼‰\")\n",
    "\n",
    "print(f\"ğŸ”§ è®¾å¤‡: {device}, æ•°æ®ç±»å‹: {torch_dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‹è½½å¹¶åŠ è½½ Qwen-Image-Edit æ¨¡å‹\n",
    "model_id = \"Qwen/Qwen-Image-Edit\"\n",
    "local_dir = './models/Qwen-Image-Edit'\n",
    "\n",
    "# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨\n",
    "if not os.path.exists(local_dir):\n",
    "    print(f\"ğŸ“¥ å¼€å§‹ä¸‹è½½ {model_id} æ¨¡å‹...\")\n",
    "    os.makedirs(os.path.dirname(local_dir), exist_ok=True)\n",
    "    snapshot_download(model_id, local_dir=local_dir)\n",
    "    print(f\"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {local_dir}\")\n",
    "else:\n",
    "    print(f\"âœ… æ¨¡å‹å·²å­˜åœ¨: {local_dir}\")\n",
    "\n",
    "# åŠ è½½ç®¡é“\n",
    "print(\"ğŸ”„ æ­£åœ¨åŠ è½½å›¾åƒç¼–è¾‘ç®¡é“...\")\n",
    "pipeline = QwenImageEditPipeline.from_pretrained(\n",
    "    local_dir, \n",
    "    torch_dtype=torch_dtype,\n",
    "    use_safetensors=True,\n",
    "    device_map=\"balanced\"\n",
    ")\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edit-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_image_with_prompt(image, prompt, seed=42, steps=50, cfg_scale=4.0):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨æç¤ºè¯ç¼–è¾‘å›¾åƒ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # å¤„ç†è¾“å…¥å›¾åƒ\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        # ç¼–è¾‘å‚æ•°\n",
    "        inputs = {\n",
    "            \"image\": image,\n",
    "            \"prompt\": prompt,\n",
    "            \"generator\": torch.manual_seed(seed),\n",
    "            \"true_cfg_scale\": cfg_scale,\n",
    "            \"negative_prompt\": \" \",\n",
    "            \"num_inference_steps\": steps,\n",
    "        }\n",
    "        \n",
    "        # æ‰§è¡Œç¼–è¾‘\n",
    "        with torch.inference_mode():\n",
    "            output = pipeline(**inputs)\n",
    "            edited_image = output.images[0]\n",
    "        \n",
    "        return edited_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç¼–è¾‘å›¾åƒæ—¶å‡ºé”™: {str(e)}\")\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradio-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»º Gradio ç•Œé¢\n",
    "def create_image_editor():\n",
    "    with gr.Blocks(title=\"Qwen å›¾åƒç¼–è¾‘å™¨\", theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # ğŸ¨ Qwen æ™ºèƒ½å›¾åƒç¼–è¾‘å™¨\n",
    "            \n",
    "            ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨æƒ³è¦çš„ç¼–è¾‘æ•ˆæœï¼ŒAI å°†ä¸ºæ‚¨æ™ºèƒ½ç¼–è¾‘å›¾åƒï¼\n",
    "            \n",
    "            **ä½¿ç”¨æ­¥éª¤ï¼š** ä¸Šä¼ å›¾åƒ â†’ è¾“å…¥ç¼–è¾‘æç¤ºè¯ â†’ ç‚¹å‡»ç¼–è¾‘æŒ‰é’®\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                # è¾“å…¥åŒºåŸŸ\n",
    "                input_image = gr.Image(\n",
    "                    label=\"ğŸ“· ä¸Šä¼ å›¾åƒ\",\n",
    "                    type=\"pil\",\n",
    "                    height=350\n",
    "                )\n",
    "                \n",
    "                prompt_input = gr.Textbox(\n",
    "                    label=\"âœï¸ ç¼–è¾‘æç¤ºè¯\",\n",
    "                    placeholder=\"è¯·è¯¦ç»†æè¿°æ‚¨æƒ³è¦çš„ç¼–è¾‘æ•ˆæœï¼Œä¾‹å¦‚ï¼šå°†èƒŒæ™¯æ”¹ä¸ºè“å¤©ç™½äº‘ï¼Œæ·»åŠ ä¸€åªå¯çˆ±çš„å°çŒ«...\",\n",
    "                    lines=3\n",
    "                )\n",
    "                \n",
    "                # å¿«é€Ÿç¤ºä¾‹æŒ‰é’®\n",
    "                gr.Markdown(\"**ğŸš€ å¿«é€Ÿç¤ºä¾‹ï¼š**\")\n",
    "                with gr.Row():\n",
    "                    btn1 = gr.Button(\"ğŸ¨ åŠ¨æ¼«é£æ ¼\", size=\"sm\")\n",
    "                    btn2 = gr.Button(\"ğŸŒ… æ—¥è½èƒŒæ™¯\", size=\"sm\")\n",
    "                    btn3 = gr.Button(\"ğŸ± æ·»åŠ å°çŒ«\", size=\"sm\")\n",
    "                    btn4 = gr.Button(\"â„ï¸ å†¬å­£é›ªæ™¯\", size=\"sm\")\n",
    "                \n",
    "                # å‚æ•°è®¾ç½®\n",
    "                with gr.Accordion(\"ğŸ›ï¸ é«˜çº§å‚æ•°\", open=False):\n",
    "                    seed_input = gr.Slider(0, 1000, value=42, step=1, label=\"éšæœºç§å­\")\n",
    "                    steps_input = gr.Slider(10, 100, value=50, step=5, label=\"æ¨ç†æ­¥æ•°\")\n",
    "                    cfg_scale_input = gr.Slider(1.0, 10.0, value=4.0, step=0.5, label=\"CFGç¼©æ”¾\")\n",
    "                \n",
    "                edit_button = gr.Button(\"ğŸ¨ å¼€å§‹ç¼–è¾‘\", variant=\"primary\", size=\"lg\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                # è¾“å‡ºåŒºåŸŸ\n",
    "                output_image = gr.Image(label=\"âœ¨ ç¼–è¾‘ç»“æœ\", height=350)\n",
    "        \n",
    "        # ç¤ºä¾‹æç¤ºè¯è¯´æ˜\n",
    "        with gr.Accordion(\"ğŸ’¡ æç¤ºè¯ç¤ºä¾‹\", open=False):\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                **é£æ ¼è½¬æ¢ï¼š**\n",
    "                - \"Transform into anime/manga style with vibrant colors\"\n",
    "                - \"Convert to oil painting style\"\n",
    "                - \"å°†è¿™å¼ ç…§ç‰‡è½¬æ¢ä¸ºæ°´å½©ç”»é£æ ¼\"\n",
    "                \n",
    "                **åœºæ™¯ç¼–è¾‘ï¼š**\n",
    "                - \"Change background to beautiful sunset\"\n",
    "                - \"Add snow and winter atmosphere\"\n",
    "                - \"å°†ç™½å¤©æ”¹ä¸ºå¤œæ™šï¼Œæ·»åŠ ç¯å…‰\"\n",
    "                \n",
    "                **å¯¹è±¡ç¼–è¾‘ï¼š**\n",
    "                - \"Add a cute cat in the foreground\"\n",
    "                - \"Remove the person from image\"\n",
    "                - \"åœ¨å›¾åƒä¸­æ·»åŠ ä¸€æœµç¾ä¸½çš„èŠ±\"\n",
    "                \"\"\"\n",
    "            )\n",
    "        \n",
    "        # ç¼–è¾‘å¤„ç†å‡½æ•°\n",
    "        def process_edit(image, prompt, seed, steps, cfg_scale, progress=gr.Progress(track_tqdm=True)):\n",
    "            if image is None:\n",
    "                return None\n",
    "            if not prompt.strip():\n",
    "                return None\n",
    "            \n",
    "            try:\n",
    "                # æ‰§è¡Œç¼–è¾‘\n",
    "                edited_image = edit_image_with_prompt(image, prompt, seed, steps, cfg_scale)\n",
    "                return edited_image\n",
    "                \n",
    "            except Exception as e:\n",
    "                return None\n",
    "        \n",
    "        \n",
    "        # ç»‘å®šäº‹ä»¶\n",
    "        edit_button.click(\n",
    "            fn=process_edit,\n",
    "            inputs=[input_image, prompt_input, seed_input, steps_input, cfg_scale_input],\n",
    "            outputs=[output_image]\n",
    "        )\n",
    "        \n",
    "        # ç¤ºä¾‹æŒ‰é’®ç»‘å®š\n",
    "        examples = [\n",
    "            \"Transform this image into anime/manga style with vibrant colors and soft lighting\",\n",
    "            \"Change the background to a beautiful sunset with warm golden and orange colors\",\n",
    "            \"Add a cute cat sitting naturally in the foreground of this image\",\n",
    "            \"Transform this scene to winter with snow covering everything\"\n",
    "        ]\n",
    "        \n",
    "        for btn, example in zip([btn1, btn2, btn3, btn4], examples):\n",
    "            btn.click(fn=lambda x=example: x, outputs=[prompt_input])\n",
    "    \n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "launch-app",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ å¯åŠ¨ Qwen å›¾åƒç¼–è¾‘å™¨...\")\n",
    "    \n",
    "demo = create_image_editor()\n",
    "\n",
    "# å¯åŠ¨ Gradio åº”ç”¨\n",
    "demo.launch(\n",
    "    share=False,          # åˆ›å»ºå…¬å…±é“¾æ¥ï¼Œä¾¿äºè¿œç¨‹è®¿é—®\n",
    "    server_name=\"0.0.0.0\",  # å…è®¸å¤–éƒ¨è®¿é—®\n",
    "    server_port=6006,    # ç«¯å£å·\n",
    "    show_error=True,     # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯\n",
    "    debug=True          # ç”Ÿäº§ç¯å¢ƒå»ºè®®å…³é—­debug\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
